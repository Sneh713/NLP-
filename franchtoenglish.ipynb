{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjQaLwzVS+u925BvCN1Lmv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9P2KBt62znw","executionInfo":{"status":"ok","timestamp":1665814802714,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}},"outputId":"82ebcbf4-d079-4405-f415-d7f4a3f0ab98"},"outputs":[{"output_type":"stream","name":"stdout","text":["hii\n"]}],"source":["print(\"hii\")"]},{"cell_type":"markdown","source":["# French To English Translator USING **LSTM**"],"metadata":{"id":"PJNe3Rhraq0x"}},{"cell_type":"markdown","source":["## important library "],"metadata":{"id":"1Usmt_iQa5jM"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, LSTM\n","import numpy as np \n","patch_size = 64 # Batch size for training.\n","epochs = 100 # Number of epochs to train for.\n","latent_dim = 256 # Latent dimensionality of the\n","num_samples = 1000 # Number of samples to train\n","# Path to the data txt file on disk.\n"],"metadata":{"id":"zTYMYeZb25dz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Set"],"metadata":{"id":"wcqPfEApbGMP"}},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","import numpy as np \n","batch_size = 64 # Batch size for training.\n","epochs = 100 # Number of epochs to train for.\n","latent_dim = 256 # Latent dimensionality of the encoding space.\n","num_samples = 10000 # Number of samples to train on.\n","# Path to the data txt file on disk.\n","data_path = \"/content/drive/MyDrive/Colab Notebooks/fra.txt\"\n"],"metadata":{"id":"SORHhDjG3Ntw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IudCI1sT3fzB","executionInfo":{"status":"ok","timestamp":1665814893116,"user_tz":-330,"elapsed":23632,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}},"outputId":"09b4272a-74a5-4acd-d71a-284f0062fba0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Test Preprocessing\n"],"metadata":{"id":"zu3EK6NlbNU3"}},{"cell_type":"code","source":["#, Vectorize the data.\n","input_texts =[]\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","  lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","  input_text, target_text, _ = line.split('\\t')\n","  # We use “tab” as the “start sequence” character\n","  # for the targets, and \"\\n\" as “end sequence” character.\n","  target_text = '\\t' + target_text + '\\n'\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    if char not in input_characters:\n","      input_characters.add(char)\n","  for char in target_text:\n","      if char not in target_characters:\n","        target_characters.add(char)"],"metadata":{"id":"mq3fQCX73YpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n"],"metadata":{"id":"r9e04udk4GRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(input_characters))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgfVqq9r5J8A","executionInfo":{"status":"ok","timestamp":1665814912699,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}},"outputId":"bf833741-07ec-4796-d0f6-c1ab26f0e075"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["71\n"]}]},{"cell_type":"code","source":["input_token_index=dict(\n","    [(char,i) for i , char in enumerate(input_characters)])\n","target_token_index=dict(\n","    [(char,i) for i, char in enumerate(target_characters)]\n",")"],"metadata":{"id":"LMJIjXdR557Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input_data = np.zeros(\n","(len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","dtype='float32')\n","\n","decoder_input_data = np.zeros(\n","(len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","dtype='float32')\n","\n","decoder_target_data = np.zeros(\n","(len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","dtype='float32') \n"],"metadata":{"id":"-0H3zCjcN8gH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  for t, char in enumerate(input_text):\n","    encoder_input_data[i, t, input_token_index[char]]=1.\n","  encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n","  for t,char in enumerate(target_text):\n","    # decoder_target_data is ahead of decoder_input_data by one timestep\n","    decoder_input_data[i, t, target_token_index[char]] = 1.\n","    if t > 0:\n","      # decoder_target_data will be ahead by one timestep\n","      # and will not include the start character.\n","      decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","  decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n","  decoder_target_data[i, t:, target_token_index[' ']] = 1.\n","\n"," \n","    \n"],"metadata":{"id":"oleOvktZTmhK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#MODEL"],"metadata":{"id":"UWezvGLLbUs-"}},{"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the \n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"WbGmlueXV4Kr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#TRAINING"],"metadata":{"id":"fIu_H1ZkbZJP"}},{"cell_type":"code","source":["# Run training\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVrDsClCXC73","executionInfo":{"status":"ok","timestamp":1665821060977,"user_tz":-330,"elapsed":5223726,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}},"outputId":"7c2f6c9a-f4ea-4257-faae-7c3573716a83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","125/125 [==============================] - 57s 429ms/step - loss: 1.1290 - val_loss: 1.0101\n","Epoch 2/100\n","125/125 [==============================] - 48s 388ms/step - loss: 0.8164 - val_loss: 0.8322\n","Epoch 3/100\n","125/125 [==============================] - 49s 394ms/step - loss: 0.6535 - val_loss: 0.6947\n","Epoch 4/100\n","125/125 [==============================] - 51s 406ms/step - loss: 0.5686 - val_loss: 0.6298\n","Epoch 5/100\n","125/125 [==============================] - 59s 472ms/step - loss: 0.5219 - val_loss: 0.5831\n","Epoch 6/100\n","125/125 [==============================] - 54s 431ms/step - loss: 0.4877 - val_loss: 0.5674\n","Epoch 7/100\n","125/125 [==============================] - 52s 414ms/step - loss: 0.4613 - val_loss: 0.5347\n","Epoch 8/100\n","125/125 [==============================] - 48s 385ms/step - loss: 0.4383 - val_loss: 0.5151\n","Epoch 9/100\n","125/125 [==============================] - 51s 412ms/step - loss: 0.4184 - val_loss: 0.5003\n","Epoch 10/100\n","125/125 [==============================] - 48s 385ms/step - loss: 0.4002 - val_loss: 0.4886\n","Epoch 11/100\n","125/125 [==============================] - 49s 391ms/step - loss: 0.3842 - val_loss: 0.4754\n","Epoch 12/100\n","125/125 [==============================] - 50s 398ms/step - loss: 0.3689 - val_loss: 0.4676\n","Epoch 13/100\n","125/125 [==============================] - 48s 386ms/step - loss: 0.3547 - val_loss: 0.4594\n","Epoch 14/100\n","125/125 [==============================] - 49s 395ms/step - loss: 0.3416 - val_loss: 0.4605\n","Epoch 15/100\n","125/125 [==============================] - 51s 412ms/step - loss: 0.3291 - val_loss: 0.4516\n","Epoch 16/100\n","125/125 [==============================] - 49s 394ms/step - loss: 0.3176 - val_loss: 0.4476\n","Epoch 17/100\n","125/125 [==============================] - 49s 396ms/step - loss: 0.3064 - val_loss: 0.4418\n","Epoch 18/100\n","125/125 [==============================] - 53s 422ms/step - loss: 0.2958 - val_loss: 0.4401\n","Epoch 19/100\n","125/125 [==============================] - 64s 514ms/step - loss: 0.2855 - val_loss: 0.4418\n","Epoch 20/100\n","125/125 [==============================] - 61s 488ms/step - loss: 0.2760 - val_loss: 0.4378\n","Epoch 21/100\n","125/125 [==============================] - 59s 471ms/step - loss: 0.2665 - val_loss: 0.4406\n","Epoch 22/100\n","125/125 [==============================] - 61s 485ms/step - loss: 0.2576 - val_loss: 0.4433\n","Epoch 23/100\n","125/125 [==============================] - 58s 465ms/step - loss: 0.2492 - val_loss: 0.4379\n","Epoch 24/100\n","125/125 [==============================] - 50s 401ms/step - loss: 0.2410 - val_loss: 0.4444\n","Epoch 25/100\n","125/125 [==============================] - 52s 420ms/step - loss: 0.2331 - val_loss: 0.4425\n","Epoch 26/100\n","125/125 [==============================] - 51s 407ms/step - loss: 0.2258 - val_loss: 0.4476\n","Epoch 27/100\n","125/125 [==============================] - 53s 425ms/step - loss: 0.2188 - val_loss: 0.4490\n","Epoch 28/100\n","125/125 [==============================] - 50s 404ms/step - loss: 0.2119 - val_loss: 0.4475\n","Epoch 29/100\n","125/125 [==============================] - 50s 400ms/step - loss: 0.2055 - val_loss: 0.4496\n","Epoch 30/100\n","125/125 [==============================] - 52s 419ms/step - loss: 0.1989 - val_loss: 0.4549\n","Epoch 31/100\n","125/125 [==============================] - 51s 409ms/step - loss: 0.1925 - val_loss: 0.4605\n","Epoch 32/100\n","125/125 [==============================] - 51s 407ms/step - loss: 0.1869 - val_loss: 0.4615\n","Epoch 33/100\n","125/125 [==============================] - 53s 424ms/step - loss: 0.1813 - val_loss: 0.4610\n","Epoch 34/100\n","125/125 [==============================] - 51s 406ms/step - loss: 0.1764 - val_loss: 0.4681\n","Epoch 35/100\n","125/125 [==============================] - 50s 398ms/step - loss: 0.1710 - val_loss: 0.4765\n","Epoch 36/100\n","125/125 [==============================] - 52s 419ms/step - loss: 0.1665 - val_loss: 0.4801\n","Epoch 37/100\n","125/125 [==============================] - 51s 407ms/step - loss: 0.1616 - val_loss: 0.4771\n","Epoch 38/100\n","125/125 [==============================] - 52s 418ms/step - loss: 0.1572 - val_loss: 0.4846\n","Epoch 39/100\n","125/125 [==============================] - 50s 402ms/step - loss: 0.1528 - val_loss: 0.4861\n","Epoch 40/100\n","125/125 [==============================] - 51s 408ms/step - loss: 0.1492 - val_loss: 0.4919\n","Epoch 41/100\n","125/125 [==============================] - 52s 416ms/step - loss: 0.1448 - val_loss: 0.4936\n","Epoch 42/100\n","125/125 [==============================] - 50s 399ms/step - loss: 0.1409 - val_loss: 0.4988\n","Epoch 43/100\n","125/125 [==============================] - 50s 401ms/step - loss: 0.1369 - val_loss: 0.5122\n","Epoch 44/100\n","125/125 [==============================] - 51s 412ms/step - loss: 0.1336 - val_loss: 0.5145\n","Epoch 45/100\n","125/125 [==============================] - 50s 397ms/step - loss: 0.1305 - val_loss: 0.5135\n","Epoch 46/100\n","125/125 [==============================] - 50s 401ms/step - loss: 0.1273 - val_loss: 0.5214\n","Epoch 47/100\n","125/125 [==============================] - 56s 450ms/step - loss: 0.1239 - val_loss: 0.5215\n","Epoch 48/100\n","125/125 [==============================] - 55s 441ms/step - loss: 0.1207 - val_loss: 0.5293\n","Epoch 49/100\n","125/125 [==============================] - 55s 438ms/step - loss: 0.1182 - val_loss: 0.5332\n","Epoch 50/100\n","125/125 [==============================] - 57s 457ms/step - loss: 0.1153 - val_loss: 0.5327\n","Epoch 51/100\n","125/125 [==============================] - 55s 444ms/step - loss: 0.1130 - val_loss: 0.5387\n","Epoch 52/100\n","125/125 [==============================] - 61s 489ms/step - loss: 0.1102 - val_loss: 0.5491\n","Epoch 53/100\n","125/125 [==============================] - 60s 478ms/step - loss: 0.1076 - val_loss: 0.5515\n","Epoch 54/100\n","125/125 [==============================] - 57s 453ms/step - loss: 0.1050 - val_loss: 0.5531\n","Epoch 55/100\n","125/125 [==============================] - 53s 423ms/step - loss: 0.1026 - val_loss: 0.5570\n","Epoch 56/100\n","125/125 [==============================] - 54s 432ms/step - loss: 0.1003 - val_loss: 0.5609\n","Epoch 57/100\n","125/125 [==============================] - 53s 428ms/step - loss: 0.0985 - val_loss: 0.5660\n","Epoch 58/100\n","125/125 [==============================] - 52s 413ms/step - loss: 0.0964 - val_loss: 0.5706\n","Epoch 59/100\n","125/125 [==============================] - 54s 432ms/step - loss: 0.0939 - val_loss: 0.5793\n","Epoch 60/100\n","125/125 [==============================] - 53s 421ms/step - loss: 0.0923 - val_loss: 0.5835\n","Epoch 61/100\n","125/125 [==============================] - 52s 419ms/step - loss: 0.0906 - val_loss: 0.5900\n","Epoch 62/100\n","125/125 [==============================] - 55s 437ms/step - loss: 0.0888 - val_loss: 0.5977\n","Epoch 63/100\n","125/125 [==============================] - 56s 452ms/step - loss: 0.0869 - val_loss: 0.6013\n","Epoch 64/100\n","125/125 [==============================] - 52s 414ms/step - loss: 0.0852 - val_loss: 0.6026\n","Epoch 65/100\n","125/125 [==============================] - 51s 409ms/step - loss: 0.0838 - val_loss: 0.6030\n","Epoch 66/100\n","125/125 [==============================] - 51s 411ms/step - loss: 0.0821 - val_loss: 0.6086\n","Epoch 67/100\n","125/125 [==============================] - 53s 423ms/step - loss: 0.0804 - val_loss: 0.6132\n","Epoch 68/100\n","125/125 [==============================] - 51s 404ms/step - loss: 0.0790 - val_loss: 0.6179\n","Epoch 69/100\n","125/125 [==============================] - 50s 400ms/step - loss: 0.0776 - val_loss: 0.6229\n","Epoch 70/100\n","125/125 [==============================] - 52s 413ms/step - loss: 0.0762 - val_loss: 0.6262\n","Epoch 71/100\n","125/125 [==============================] - 50s 398ms/step - loss: 0.0747 - val_loss: 0.6308\n","Epoch 72/100\n","125/125 [==============================] - 50s 399ms/step - loss: 0.0737 - val_loss: 0.6404\n","Epoch 73/100\n","125/125 [==============================] - 52s 413ms/step - loss: 0.0722 - val_loss: 0.6402\n","Epoch 74/100\n","125/125 [==============================] - 50s 399ms/step - loss: 0.0708 - val_loss: 0.6456\n","Epoch 75/100\n","125/125 [==============================] - 50s 400ms/step - loss: 0.0696 - val_loss: 0.6505\n","Epoch 76/100\n","125/125 [==============================] - 52s 416ms/step - loss: 0.0688 - val_loss: 0.6548\n","Epoch 77/100\n","125/125 [==============================] - 50s 402ms/step - loss: 0.0675 - val_loss: 0.6536\n","Epoch 78/100\n","125/125 [==============================] - 52s 415ms/step - loss: 0.0661 - val_loss: 0.6611\n","Epoch 79/100\n","125/125 [==============================] - 50s 400ms/step - loss: 0.0651 - val_loss: 0.6608\n","Epoch 80/100\n","125/125 [==============================] - 51s 405ms/step - loss: 0.0641 - val_loss: 0.6641\n","Epoch 81/100\n","125/125 [==============================] - 52s 417ms/step - loss: 0.0630 - val_loss: 0.6709\n","Epoch 82/100\n","125/125 [==============================] - 50s 401ms/step - loss: 0.0621 - val_loss: 0.6714\n","Epoch 83/100\n","125/125 [==============================] - 51s 404ms/step - loss: 0.0612 - val_loss: 0.6779\n","Epoch 84/100\n","125/125 [==============================] - 53s 421ms/step - loss: 0.0603 - val_loss: 0.6798\n","Epoch 85/100\n","125/125 [==============================] - 52s 416ms/step - loss: 0.0594 - val_loss: 0.6846\n","Epoch 86/100\n","125/125 [==============================] - 51s 409ms/step - loss: 0.0583 - val_loss: 0.6896\n","Epoch 87/100\n","125/125 [==============================] - 53s 423ms/step - loss: 0.0578 - val_loss: 0.6915\n","Epoch 88/100\n","125/125 [==============================] - 51s 407ms/step - loss: 0.0569 - val_loss: 0.6945\n","Epoch 89/100\n","125/125 [==============================] - 52s 420ms/step - loss: 0.0560 - val_loss: 0.6956\n","Epoch 90/100\n","125/125 [==============================] - 51s 409ms/step - loss: 0.0550 - val_loss: 0.6966\n","Epoch 91/100\n","125/125 [==============================] - 51s 407ms/step - loss: 0.0546 - val_loss: 0.7031\n","Epoch 92/100\n","125/125 [==============================] - 52s 418ms/step - loss: 0.0534 - val_loss: 0.7073\n","Epoch 93/100\n","125/125 [==============================] - 51s 406ms/step - loss: 0.0529 - val_loss: 0.7069\n","Epoch 94/100\n","125/125 [==============================] - 51s 404ms/step - loss: 0.0523 - val_loss: 0.7053\n","Epoch 95/100\n","125/125 [==============================] - 52s 419ms/step - loss: 0.0517 - val_loss: 0.7077\n","Epoch 96/100\n","125/125 [==============================] - 50s 403ms/step - loss: 0.0508 - val_loss: 0.7164\n","Epoch 97/100\n","125/125 [==============================] - 50s 398ms/step - loss: 0.0504 - val_loss: 0.7211\n","Epoch 98/100\n","125/125 [==============================] - 52s 414ms/step - loss: 0.0493 - val_loss: 0.7199\n","Epoch 99/100\n","125/125 [==============================] - 50s 404ms/step - loss: 0.0488 - val_loss: 0.7299\n","Epoch 100/100\n","125/125 [==============================] - 52s 420ms/step - loss: 0.0484 - val_loss: 0.7321\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6b269b2f10>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"metadata":{"id":"B0xtqvLvXHSZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TESTING"],"metadata":{"id":"Y0LeWsO6bg1P"}},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"metadata":{"id":"Ivsdjz49XNYo","executionInfo":{"status":"ok","timestamp":1665822152723,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["##LINK FOR DATASET AND EXPLATION OF CODE "],"metadata":{"id":"vHnuESA2bk7Q"}},{"cell_type":"markdown","source":["https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"],"metadata":{"id":"OMZomACUYZG4"}},{"cell_type":"code","source":["\"\"\"for seq_index in range(100):\n","  # Take one sequence (part of the training set)\n","  # for trying out decoding.\n","  input_seq = (encoder_input_data[seq_index: seq_index+1]).astype(int)\n","  #decoded_sentence= decode_sequence(input_seq)\n","  #print(\"hello\")\n","  #print('Input sentence:',input_texts[input_seq.astype(int)])\n","  print('Input sentence:',input_texts[input_seq])\n","  print('Decoded sentence:', decode_sequence(input_seq))\"\"\"\n","  \n","\n"," \n"],"metadata":{"id":"X3FqykbHX9_g","executionInfo":{"status":"ok","timestamp":1665823040015,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}},"colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"75cdfa9f-9cc4-450e-d308-cec75b47357d"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'for seq_index in range(100):\\n  # Take one sequence (part of the training set)\\n  # for trying out decoding.\\n  input_seq = (encoder_input_data[seq_index: seq_index+1]).astype(int)\\n  #decoded_sentence= decode_sequence(input_seq)\\n  #print(\"hello\")\\n  #print(\\'Input sentence:\\',input_texts[input_seq.astype(int)])\\n  print(\\'Input sentence:\\',input_texts[input_seq])\\n  print(\\'Decoded sentence:\\', decode_sequence(input_seq))'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":[],"metadata":{"id":"hKaEMT8GsLa2","executionInfo":{"status":"ok","timestamp":1665822661533,"user_tz":-330,"elapsed":478,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["#print('Input sentence:',input_texts[seq_index])"],"metadata":{"id":"4_c713_iv09o","executionInfo":{"status":"ok","timestamp":1665822448572,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sneh Singh","userId":"10184239061002940930"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ExcENGO7wI4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dEZAxoq-wOr1"},"execution_count":null,"outputs":[]}]}